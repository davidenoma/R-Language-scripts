---
title: Linear regression in R
author: Jeff Leek
output:
  rmarkdown::html_document:
    toc: true
  vignette: >  
    %\VignetteIndexEntry{Linear regression example}
    %\VignetteEngine{knitr::rmarkdown}
    \usepackage[utf8]{inputenc}
---

```{r front, child="./../front.Rmd", echo=FALSE}
```


## Dependencies

This document depends on the following packages:

```{r load_hidden, echo=FALSE, results="hide", warning=FALSE}
suppressPackageStartupMessages({
  library(devtools)
  library(Biobase)
  library(broom)
})
```

```{r load}
  library(devtools)
  library(Biobase)
  library(broom)
```

To install these packages you can use the code (or if you are compiling the document, remove the `eval=FALSE` from the chunk.)

```{r install_packages, eval=FALSE}
install.packages(c("devtools","broom"))
source("http://www.bioconductor.org/biocLite.R")
biocLite(c("Biobase"))
```

## Download the data


Here we are going to use some data from the paper [Detection of redundant fusion transcripts as biomarkers or disease-specific therapeutic targets in breast cancer.](http://www.ncbi.nlm.nih.gov/pubmed/22496456) that uses data from different normal human tissues (called the Illumina BodyMap data).

```{r}
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
bm = bodymap.eset
pdata=pData(bm)
edata=as.data.frame(exprs(bm))
fdata = fData(bm)
ls()
```

## Fit a simple linear regression

Here we regress the counts for the first gene on the age of the people from whom the tissue was drawn. 

```{r}
edata = as.matrix(edata)
lm1 = lm(edata[1,] ~ pdata$age)
tidy(lm1)
```

## Is fitting the line a good idea?

Visual diagnostics are often some of the most helpful 

```{r}
plot(pdata$age,edata[1,], col=1)
abline(lm1$coeff[1],lm1$coeff[2], col=2,lwd=3)
```

## What about categorical variables?

```{r}
pdata$gender
table(pdata$gender)
```

## Visualize the difference between genders

```{r}
boxplot(edata[1,] ~ pdata$gender)
points(edata[1,] ~ jitter(as.numeric(pdata$gender)),
       col=as.numeric(pdata$gender))
```


## "dummy" variables

```{r}
dummy_m = pdata$gender=="M"
dummy_m

dummy_f = pdata$gender=="F"
dummy_f
```

## R's modeling formulae do this for you automatically

```{r}
lm2 = lm(edata[1,] ~ pdata$gender)
tidy(lm2)
```

## Peaking "under the hood" of the variables used in the model

```{r}
mod2 = model.matrix(~pdata$gender)
mod2
```

## Categorical variables with multiple levels

```{r}
table(pdata$tissue.type)
pdata$tissue.type == "adipose"
pdata$tissue.type == "adrenal"
```

## This leads to multiple coefficients for one variable

```{r}
tidy(lm(edata[1,] ~ pdata$tissue.type ))
```

## Adjusting for variables

```{r}
lm3 = lm(edata[1,] ~ pdata$age + pdata$gender)
tidy(lm3)
```

## Interactions (careful!)

You can add interaction terms, but there are a couple of things to keep in mind:

* Interpretation can be challenging
* You should always also include main effects
* Interactions in genomics data are in general hard to detect, and can be fraught for example in gene by environment interactions, the interaction term only tells you that there may be an association, but there are lots of reasons for this statistical association that aren't biological interaction. 

```{r}
lm4 = lm(edata[1,] ~ pdata$age*pdata$gender)
tidy(lm4)
```


## A few things to be aware of

Outliers can have a big impact on the regression, depending on where they land. Here there isn't much impact

```{r}
lm4 = lm(edata[6,] ~ pdata$age)
plot(pdata$age,edata[6,],col=2)
abline(lm4,col=1,lwd=3)
```

But in this case there is a huge impact

```{r}
index = 1:19
lm5 = lm(edata[6,] ~ index)
plot(index,edata[6,],col=2)
abline(lm5,col=1,lwd=3)

lm6 = lm(edata[6,-19] ~ index[-19])
abline(lm6,col=3,lwd=3)

legend(5,1000,c("With outlier","Without outlier"),col=c(1,3),lwd=3)

```

In general you'd like your residuals to looks symmetrically (e.g. approximately Normally) distributed but they aren't here. Outliers in the residuals aren't great either. 

```{r}
par(mfrow=c(1,2))
hist(lm6$residuals,col=2)
hist(lm5$residuals,col=3)
```

Data transforms are often applied before regression and the residuals look a little better here. 

```{r}
gene1 = log2(edata[1,]+1)
lm7 = lm(gene1 ~ index)
hist(lm7$residuals,col=4)
```


Be careful when two variables in your regression model are very highly correlated. This is called co-linearity and can lead to highly variable and uninterpretable results. R fails "gracefully" (i.e. doesn't tell you) when this happens so you have to check by hand. This is also a problem if you fit too many variables for example. 

```{r}
lm8 = lm(gene1 ~ pdata$tissue.type + pdata$age)
tidy(lm8)
```


Another good idea is to look for "patterns" in the residuals

```{r}
colramp = colorRampPalette(1:4)(17)
lm9 = lm(edata[2,] ~ pdata$age)
plot(lm9$residuals,col=colramp[as.numeric(pdata$tissue.type)])
```


## Notes and further reading

This is of course a ridiculously brief introduction to linear models. The main thing to keep in mind is that you should visually inspect the model fits, consider the scale you are measuring on, and evaluate whether the covariates are related in ways that are normal to you. Here are some places to learn a lot more about linear models

* [Regression Models (Coursera)](https://www.coursera.org/course/regmods)
* [Introduction to linear models and matrix algebra (EdX)](http://online-learning.harvard.edu/course/introduction-linear-models-and-matrix-algebra)

## Session information

Here is the session information 

```{r session_info}
devtools::session_info()
```

It is also useful to compile the time the document was processed. This document was processed on: `r Sys.Date()`.



